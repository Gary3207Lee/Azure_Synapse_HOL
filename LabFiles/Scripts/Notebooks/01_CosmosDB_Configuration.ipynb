{
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "sessionKeepAliveTimeout": 30,
    "saveOutput": true
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Load the IoTDeviceInfo dataset from ADLS Gen2 to a dataframe\n",
        ">The Synapse workspace is attached to an ADLS Gen2 storage account and the files placed on the default storage account can be accessed using the relative path as below.\n",
        "&nbsp;\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool",
              "session_id": 1,
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-01-17T02:31:32.8811914Z",
              "execution_start_time": "2021-01-17T02:34:16.6487552Z",
              "execution_finish_time": "2021-01-17T02:34:31.089772Z"
            },
            "text/plain": "StatementMeta(sparkpool, 1, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "dfDeviceInfo = (spark\n",
        "                .read\n",
        "                .csv(\"abfss://cosmosdemo@<ADLS Gen2 Account Name>.dfs.core.windows.net/SynapseDemoIoT/IoTDeviceInfo.csv\", header=True)\n",
        "              )\n",
        "\n",
        "dfSignals = (spark\n",
        "                .read\n",
        "                .csv(\"abfss://cosmosdemo@<ADLS Gen2 Account Name>.dfs.core.windows.net/SynapseDemoIoT/IoTSignals.csv\", header=True)\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "dfProducts = (spark\r\n",
        "                .read\r\n",
        "                .csv(\"abfss://cosmosdemo@<ADLS Gen2 Account Name>.dfs.core.windows.net/SynapseDemoRetail/Products.csv\", header=True)\r\n",
        "              )\r\n",
        "\r\n",
        "dfRetailSales = (spark\r\n",
        "                .read\r\n",
        "                .csv(\"abfss://cosmosdemo@<ADLS Gen2 Account Name>.dfs.core.windows.net/SynapseDemoRetail/RetailSales.csv\", header=True)\r\n",
        "              )\r\n",
        "\r\n",
        "dfStoreDemographics = (spark\r\n",
        "                .read\r\n",
        "                .csv(\"abfss://cosmosdemo@<ADLS Gen2 Account Name>.dfs.core.windows.net/SynapseDemoRetail/StoreDemoGraphics.csv\", header=True)\r\n",
        "              )\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Write the dataframe to the Azure Cosmos DB collection\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool",
              "session_id": 1,
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-01-17T02:36:52.1888241Z",
              "execution_start_time": "2021-01-17T02:36:52.2274637Z",
              "execution_finish_time": "2021-01-17T02:37:16.6831839Z"
            },
            "text/plain": "StatementMeta(sparkpool, 1, 5, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "dfDeviceInfo.write\\\n",
        "            .format(\"cosmos.oltp\")\\\n",
        "            .option(\"spark.synapse.linkedService\", \"CosmosDemo\")\\\n",
        "            .option(\"spark.cosmos.container\", \"IoTDeviceInfo\")\\\n",
        "            .option(\"spark.cosmos.write.upsertEnabled\", \"true\")\\\n",
        "            .mode('append')\\\n",
        "            .save()\n",
        "\n",
        "dfSignals.write\\\n",
        "            .format(\"cosmos.oltp\")\\\n",
        "            .option(\"spark.synapse.linkedService\", \"CosmosDemo\")\\\n",
        "            .option(\"spark.cosmos.container\", \"IoTSignals\")\\\n",
        "            .option(\"spark.cosmos.write.upsertEnabled\", \"true\")\\\n",
        "            .mode('append')\\\n",
        "            .save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "dfProducts.write\\\r\n",
        "            .format(\"cosmos.oltp\")\\\r\n",
        "            .option(\"spark.synapse.linkedService\", \"CosmosDemo\")\\\r\n",
        "            .option(\"spark.cosmos.container\", \"RetailProducts\")\\\r\n",
        "            .option(\"spark.cosmos.write.upsertEnabled\", \"true\")\\\r\n",
        "            .mode('append')\\\r\n",
        "            .save()\r\n",
        "\r\n",
        "dfRetailSales.write\\\r\n",
        "            .format(\"cosmos.oltp\")\\\r\n",
        "            .option(\"spark.synapse.linkedService\", \"CosmosDemo\")\\\r\n",
        "            .option(\"spark.cosmos.container\", \"RetailSales\")\\\r\n",
        "            .option(\"spark.cosmos.write.upsertEnabled\", \"true\")\\\r\n",
        "            .mode('append')\\\r\n",
        "            .save()\r\n",
        "\r\n",
        "dfStoreDemographics.write\\\r\n",
        "            .format(\"cosmos.oltp\")\\\r\n",
        "            .option(\"spark.synapse.linkedService\", \"CosmosDemo\")\\\r\n",
        "            .option(\"spark.cosmos.container\", \"RetailStoreDemographics\")\\\r\n",
        "            .option(\"spark.cosmos.write.upsertEnabled\", \"true\")\\\r\n",
        "            .mode('append')\\\r\n",
        "            .save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Simulate streaming data generation using Rate streaming source\n",
        "* The Rate streaming source is used to simplify the solution here and can be replaced with any supported streaming sources such as [Azure Event Hubs](https://azure.microsoft.com/en-us/services/event-hubs/) and [Apache Kafka](https://docs.microsoft.com/en-us/azure/hdinsight/kafka/apache-kafka-introduction).\n",
        "\n",
        "\n",
        ">The Rate streaming source generates data at the specified number of rows per second and each output row contains a timestamp and value.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool",
              "session_id": 1,
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-01-17T02:37:40.3407627Z",
              "execution_start_time": "2021-01-17T02:37:40.3766031Z",
              "execution_finish_time": "2021-01-17T02:37:42.422147Z"
            },
            "text/plain": "StatementMeta(sparkpool, 1, 6, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "dfStream = (spark\n",
        "                .readStream\n",
        "                .format(\"rate\")\n",
        "                .option(\"rowsPerSecond\", 10)\n",
        "                .load()\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Format the stream dataframe as per the IoTSignals schema\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool",
              "session_id": 1,
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-01-17T02:37:44.6903434Z",
              "execution_start_time": "2021-01-17T02:37:44.731744Z",
              "execution_finish_time": "2021-01-17T02:37:46.766189Z"
            },
            "text/plain": "StatementMeta(sparkpool, 1, 7, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import StringType\n",
        "import uuid\n",
        "\n",
        "numberOfDevices = 10\n",
        "generate_uuid = F.udf(lambda : str(uuid.uuid4()), StringType())\n",
        "              \n",
        "dfIoTSignals = (dfStream\n",
        "                    .withColumn(\"id\", generate_uuid())\n",
        "                    .withColumn(\"dateTime\", dfStream[\"timestamp\"].cast(StringType()))\n",
        "                    .withColumn(\"deviceId\", F.concat(F.lit(\"dev-\"), F.expr(\"mod(value, %d)\" % numberOfDevices)+1))\n",
        "                    .withColumn(\"measureType\", F.expr(\"CASE WHEN rand() < 0.5 THEN 'Rotation Speed' ELSE 'Output' END\"))\n",
        "                    .withColumn(\"unitSymbol\", F.expr(\"CASE WHEN rand() < 0.5 THEN 'RPM' ELSE 'MW' END\"))\n",
        "                    .withColumn(\"unit\", F.expr(\"CASE WHEN rand() < 0.5 THEN 'Revolutions per Minute' ELSE 'MegaWatts' END\"))\n",
        "                    .withColumn(\"measureValue\", F.expr(\"CASE WHEN rand() > 0.9 THEN value * 2 WHEN rand() < 0.1 THEN value div 2 ELSE value END\"))\n",
        "                    .drop(\"timestamp\")\n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Stream writes to the Azure Cosmos DB Collection\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "sparkpool",
              "session_id": 1,
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "cancelled",
              "queued_time": "2021-01-17T02:38:10.4579101Z",
              "execution_start_time": "2021-01-17T02:38:10.5058583Z",
              "execution_finish_time": "2021-01-17T02:38:59.8656636Z"
            },
            "text/plain": "StatementMeta(sparkpool, 1, 8, Finished, Cancelled)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "streamQuery = dfIoTSignals\\\n",
        "        .writeStream\\\n",
        "        .format(\"cosmos.oltp\")\\\n",
        "        .outputMode(\"append\")\\\n",
        "        .option(\"checkpointLocation\", \"/writeCheckpointDir\")\\\n",
        "        .option(\"spark.synapse.linkedService\", \"CosmosDemo\")\\\n",
        "        .option(\"spark.cosmos.container\", \"IoTStreamingSignals\")\\\n",
        "        .option(\"spark.cosmos.connection.mode\", \"gateway\")\\\n",
        "        .start()\n",
        "\n",
        "streamQuery.awaitTermination()"
      ]
    }
  ]
}