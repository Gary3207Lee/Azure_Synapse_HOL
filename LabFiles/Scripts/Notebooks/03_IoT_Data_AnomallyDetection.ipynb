{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Loda the data in Cosmos DB Analytical store collection \n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "df_IoTSignals = spark.read\\\n",
        "                    .format(\"cosmos.olap\")\\\n",
        "                    .option(\"spark.synapse.linkedService\", \"CosmosDemoIoT\")\\\n",
        "                    .option(\"spark.cosmos.container\", \"IoTSignals\")\\\n",
        "                    .load()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Data exploration using pyplot\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_IoTSignals_pd = df_IoTSignals.toPandas()\n",
        "df_dev = df_IoTSignals_pd[(df_IoTSignals_pd.deviceId == \"dev-1\")]\n",
        "df_dev = df_dev.dropna()\n",
        "df_dev = df_dev.astype({\"measureValue\": int})\n",
        "#display(df_dev)\n",
        "df_dev = df_dev.pivot(index='dateTime', columns = 'unitSymbol' , values =  'measureValue')\n",
        "df_dev['timestamp']=df_dev.index\n",
        "df_dev['index']=list(range(len(df_dev)))\n",
        "df_dev.set_index('index',inplace=True)\n",
        "df_dev.plot(y='MW', x= 'timestamp', color='green',figsize=(20,5), label = 'Output MW')\n",
        "plt.title('MW TimeSeries')\n",
        "df_dev.plot(y='RPM', x= 'timestamp', color='black', figsize=(20,5), label = 'RPM')\n",
        "plt.title('RPM TimeSeries')\n",
        "plt.legend(loc = 'best')\n",
        "plt.show()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Perform anomaly detection using Microsoft Machine Learning for Spark (MMLSpark)\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import col\n",
        "from mmlspark.cognitive import SimpleDetectAnomalies\n",
        "from mmlspark.core.spark import FluentAPI\n",
        "\n",
        "anomaly_detector = (SimpleDetectAnomalies()\n",
        "                            .setSubscriptionKey(\"7a20deaa1907472f96b767cf14d0f73d\")\n",
        "                            .setUrl(\"<Azure Anomaly Detector End Point>anomalydetector/v1.0/timeseries/entire/detect\")\n",
        "                            .setOutputCol(\"anomalies\")\n",
        "                            .setGroupbyCol(\"grouping\")\n",
        "                            .setSensitivity(95)\n",
        "                            .setGranularity(\"secondly\"))\n",
        "\n",
        "df_anomaly = (df_IoTSignals\n",
        "                    .where(col(\"unitSymbol\") == 'RPM')\n",
        "                    .withColumnRenamed(\"dateTime\", \"timestamp\")\n",
        "                    .withColumn(\"value\", col(\"measureValue\").cast(\"double\"))\n",
        "                    .withColumn(\"grouping\", col(\"deviceId\"))\n",
        "                    .mlTransform(anomaly_detector))\n",
        "\n",
        "df_anomaly.createOrReplaceTempView('df_anomaly')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "display(df_anomaly)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Format the dataframe for visualization\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "df_anomaly_single_device = spark.sql(\"select timestamp \\\n",
        "                                            , measureValue \\\n",
        "                                            , anomalies.expectedValue \\\n",
        "                                            , anomalies.expectedValue + anomalies.upperMargin as expectedUpperValue \\\n",
        "                                            , anomalies.expectedValue - anomalies.lowerMargin as expectedLowerValue \\\n",
        "                                            , case when anomalies.isAnomaly=true then 1 else 0 end as isAnomaly \\\n",
        "                                        from df_anomaly \\\n",
        "                                        where deviceid = 'dev-1' and timestamp < '2020-12-29'\\\n",
        "                                        order by timestamp \\\n",
        "                                        limit 200\")\n",
        "\n",
        "display(df_anomaly_single_device)  "
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Visualize the anomalies using plotly\n",
        "* Plot Expected value, Upper Value, Lower Value and Actual Value along with Anomaly flag\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import chart_studio.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import plot\n",
        "import matplotlib.pyplot as plt\n",
        "from pyspark.sql.functions import col\n",
        "from matplotlib.pyplot import figure\n",
        " \n",
        "adf = df_anomaly_single_device.toPandas()\n",
        "adf_subset = df_anomaly_single_device.where(col(\"isAnomaly\") == 1).toPandas() \n",
        "\n",
        "plt.figure(figsize=(23,8))\n",
        "plt.plot(adf['timestamp'],adf['expectedUpperValue'], color='darkred', linestyle='solid', linewidth=0.25)\n",
        "plt.plot(adf['timestamp'],adf['expectedValue'], color='darkgreen', linestyle='solid', linewidth=2)\n",
        "plt.plot(adf['timestamp'],adf['measureValue'], 'b', color='royalblue', linestyle='dotted', linewidth=2)\n",
        "plt.plot(adf['timestamp'],adf['expectedLowerValue'],  color='black', linestyle='solid', linewidth=0.25)\n",
        "plt.plot(adf_subset['timestamp'],adf_subset['measureValue'], 'ro')\n",
        "plt.legend(['RPM-UpperMargin', 'RPM-ExpectedValue', 'RPM-ActualValue', 'RPM-LowerMargin', 'RPM-Anomaly'])\n",
        "plt.title('RPM Anomalies with Expected, Actual, Upper and Lower Values')\n",
        "plt.show()"
      ],
      "attachments": {}
    }
  ]
}